# -*- coding: utf-8 -*-
"""ia-project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/196EG_en_pIPolz8CAjrN-ekQeyyNQ054
"""

#@title **Montando el drive** { display-mode: "form" }
import os
from google.colab import drive
drive.mount('/content/drive')
os.chdir('/content/drive/My Drive/IA-PROJECT')
print(os.getcwd())

#@title **Cargando libreria** { display-mode: "form" }

from __future__ import division, print_function, unicode_literals
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import normalize
import sklearn.metrics as metrics
from sklearn.svm import SVR
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
import seaborn as sns
sns.set_theme()
from sklearn.model_selection import KFold
from sklearn.metrics import *
import scipy.stats as stats
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

#@title **Importando el conjunto de datos de Matematicas**
data_1 = pd.read_csv("csv/student-mat.csv", sep=";" )
X1 = data_1.values[:,:-1]
y1 = data_1.values[:,-1]
print(X1.shape, y1.shape)
data_1.head()

#@title **Importando el conjunto de datos de Portugues**
data_2 = pd.read_csv("csv/student-por.csv", sep=";" )
X2 = data_2.values[:,:-1]
y2 = data_2.values[:,-1]
print(X2.shape, y2.shape)
data_2.head()

#@title **Explorando metricas de Matematicas**
data_1.describe().T

#@title **Explorando metricas de Portugues**
data_2.describe().T

#@title **Informacion del tipo de datos de Matematicas**
data_1.info()

#@title **Informacion del tipo de datos de Portugues**
data_2.info()

#@title Cambiamos las propiedades objeto en caracteristica por categoria
for labels, content in data_1.items():
    if pd.api.types.is_string_dtype(content):
        data_1[labels] = content.astype("category").cat.as_ordered()

data_1.info()

#@title **Ahora los valores de nuestras categorias los cambiamos a valores numericos tratables**
for labels, content in data_1.items():
    if not pd.api.types.is_numeric_dtype(content):
        data_1[labels] = pd.Categorical(content).codes

data_1.head()

#@title **Cambiamos las propiedades objeto en caracteristica por categoria**
for labels, content in data_2.items():
    if pd.api.types.is_string_dtype(content):
        data_2[labels] = content.astype("category").cat.as_ordered()

data_2.info()

#@title **Ahora los valores de nuestras categorias los cambiamos a valores numericos tratables**
for labels, content in data_2.items():
    if not pd.api.types.is_numeric_dtype(content):
        data_2[labels] = pd.Categorical(content).codes

data_2.head()

#@title Correlacion del conjunto de datos de Matematicas
data_1.corr()

plt.figure(figsize=(30,10), dpi=100)
sns.heatmap(data_1.corr(), cmap='plasma', annot=True)

#@title Correlacion del conjunto de datos de Portugues
data_2.corr()

plt.figure(figsize=(30,10), dpi=100)
sns.heatmap(data_2.corr(), cmap='plasma', annot=True)

"""Como G1 y G2 estÃ¡n altamente correlacionados con G3, nuestra caracteristica objetivo, descartaremos G1 y G2 para el entrenamiento."""

#@title **Separamos los datos en X , y**
X1 = data_1.drop(['G1','G2','G3'], axis=1)
y1 = data_1['G3']

#@title **Separamos los datos en X , y**
X2 = data_2.drop(['G1','G2','G3'], axis=1)
y2 = data_2['G3']

X1.head()

y1

X2.head()

y2

#@title **Renombramos para diferenciar facilmente las columnas de notas en los cursos**
data_1.rename(columns={"G1": "G1_mat", "G2": "G2_mat","G3":"G3_mat"},inplace=True)
data_1.head()

#@title **Renombramos para diferenciar facilmente las columnas de notas en los cursos**
data_2.rename(columns={"G1": "G1_por", "G2": "G2_por","G3":"G3_por"},inplace=True)
data_2.head()

#@title **Agregamos una columna nueva a nuestro dataset que contiene el promedio para mas adelante explorarla**
data_1['Aveare_grades'] = data_1[['G1_mat','G2_mat','G3_mat']].mean(axis=1)
data_2['Aveare_grades'] = data_2[['G1_por','G2_por','G3_por']].mean(axis=1)

#@title **Encontramos una relacion entre la edad y el promedio de las notas donde los estudiantes de entre 19 y 20 anios tienen un rendimiento mejor con respecto a los demas en el conjuntos de datos de la materia Matematicas**
sns.relplot(data = data_1, y='Aveare_grades', x='age', kind="line")

#@title **Encontramos una relacion entre la edad y el promedio de las notas donde los estudiantes de 19 anios tienen califaciones atipicamente mas bajas que los demas en el conjunto de datos de la materia Portugues**
sns.relplot(data = data_2, y='Aveare_grades', x='age', kind="line")

plt.figure(figsize=(8,5))
sns.violinplot(x="age", y="Aveare_grades", hue="sex",
                    data=data_1, palette="Set2", split=True,
                    scale="count")

plt.figure(figsize=(8,5))
sns.violinplot(x="age", y="Aveare_grades", hue="sex",
                    data=data_2, palette="Set2", split=True,
                    scale="count")

#@title **Normalizamos nuestro ground truth y la columna edad**
data_1[['age','G3_mat']] = normalize(data_1[['age','G3_mat']])
data_2[['age','G3_por']] = normalize(data_2[['age','G3_por']])

data_1

data_2

#@title **Eliminanos del conjuntos de datos de estudio las columnas G1 y G2 que estan altamente relacionadas con nuestro groun truth**
X1 = data_1.drop(data_1[['G1_mat','G2_mat','G3_mat']],axis = 1)
y1 = data_1['G3_mat']
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.3, random_state=21)

#@title **Eliminanos del conjuntos de datos de estudio las columnas G1 y G2 que estan altamente relacionadas con nuestro groun truth**
X2 = data_2.drop(data_2[['G1_por','G2_por','G3_por']],axis = 1)
y2 = data_2['G3_por']
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.3, random_state=21)

#@title **Funcion que nos retorna metricas para estudiar el rendimiento de cada estimador de regresion**
def regression_results(y_true, y_pred):
    #Metricas de la regresion
    explained_variance=metrics.explained_variance_score(y_true, y_pred)
    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) 
    mse=metrics.mean_squared_error(y_true, y_pred) 
    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)
    print('explained_variance: ', round(explained_variance,4))    
    print('MAE: ', round(mean_absolute_error,4))
    print('MSE: ', round(mse,4))
    print('RMSE: ', round(np.sqrt(mse),4))

#@title ***Random Forest Regressor***
est1 = RandomForestRegressor()
est1.fit(X1_train,y1_train)
regression_results(y1_test,est1.predict(X1_test))

#@title ***Random Forest Regressor***
est2 = RandomForestRegressor()
est2.fit(X2_train,y2_train)
regression_results(y2_test,est2.predict(X2_test))

#@title ***Decision Tree Regressor***
est1DTR = DecisionTreeRegressor()
est1DTR.fit(X1_train, y1_train)
regression_results(y1_test, est1DTR.predict(X1_test))

#@title ***Decision Tree Regressor***
est2DTR = DecisionTreeRegressor()
est2DTR.fit(X2_train, y2_train)
regression_results(y2_test, est2DTR.predict(X2_test))

#@title ***SVR con kernels diferentes***
kernels = ['linear', 'poly','rbf']
for k in kernels:
  est1SVR = SVR(kernel=k)
  est1SVR.fit(X1_train, y1_train)
  print(k)
  regression_results(y1_test,est1SVR.predict(X1_test))

#@title ***SVR con kernels diferentes***
kernels = ['linear', 'poly','rbf']
for k in kernels:
  est2SVR = SVR(kernel=k)
  est2SVR.fit(X2_train, y2_train)
  print(k)
  regression_results(y2_test,est1SVR.predict(X2_test))

#@title ***Deep Learning***
import tensorflow as tf
from tensorflow import keras

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(optimizer=tf.keras.optimizers.SGD(), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(X1_train, y1_train, epochs=5)
test_loss, test_acc = model.evaluate(X1_test, y1_test)

print('Test accuracy:', test_acc)

#@title **Interaccion** - Ahora para interacion indicaras un indice cualquiera el cual sera consultado en nuestro Dataset y comparado con la prediccion de nuestra regresion
index =    1#@param {type:"integer"}
dataset =  1#@param {type: "integer"}
#@markdown ### 1: RandomForestRegressor 2: DecisionTreeRegressor 3: SupportVectorRegressor
estimator =  1#@param {type: "integer"}
RFR = RandomForestRegressor()
DTR = DecisionTreeRegressor()
svr = SVR()
i = estimator - 1
estimators = [RFR, DTR, svr]

def prediction(est, index, x_test, y_test):
  y_pred = est.predict(x_test)
  arr = y_test.to_numpy()
  print("Prediccion en el indice "+ str(index) + ": "+ str(y_pred[index])+" - "+"ground truth en el indice: "+str(arr[index]))

if (i > len(estimators) or i <= -1):
  print("No se ingreso un estimador correcto")
else:
  est = estimators[i]
  if dataset == 1:
    est.fit(X1_train, y1_train)
    prediction(est, index, X1_test, y1_test)
  elif dataset == 2:
    est.fit(X2_train, y2_train)
    prediction(est, index, X2_test, y2_test)
  else:
    print("Error! #$%&$%*$%@%#@*(")